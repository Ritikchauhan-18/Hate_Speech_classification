# -*- coding: utf-8 -*-
"""Transformer_BERT_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l19s9D8iRUuRLIBwMGzBPQgULcKJv7IT
"""

!pip install datasets

import pandas as pd
import datasets
from transformers import AutoTokenizer
import re

df = pd.read_excel('/content/hatespeechdata.xlsx')
df.head()



def preprocess_text(tweet):
  if isinstance(tweet, str):
    return re.sub(r'@\w+', '', tweet)
  return ''

df['cleaned_tweet'] = df['tweet'].apply(lambda text: preprocess_text(text))

df.cleaned_tweet[0]

df.head()

from datasets import Dataset
from datasets import DatasetDict

dataset = Dataset.from_pandas(df)
dataset[0]

train_test_valid = dataset.train_test_split()
test_valid = train_test_valid['test'].train_test_split()

train_test_valid_dataset = DatasetDict({
    'train': train_test_valid['train'],
    'test' : test_valid['test'],
    'valid' : test_valid['train']
})

dataset = train_test_valid_dataset.remove_columns(['offensive_language', 'neither', 'Unnamed: 0', 'hate_speech', 'count'])

dataset

model = 'bert-base-cased'

tokenizer = AutoTokenizer.from_pretrained(model)

def tokenized_function(train_dataset):
    return tokenizer(train_dataset['cleaned_tweet'], padding = 'max_length')

tokenized_dataset = dataset.map(tokenized_function, batched = True)

train_dataset = tokenized_dataset['train']
test_dataset = tokenized_dataset['test']
valid_dataset = tokenized_dataset['valid']

train_dataset



train_dataset = train_dataset.remove_columns(['tweet', 'cleaned_tweet']).with_format('tensorflow')
valid_dataset = valid_dataset.remove_columns(['tweet', 'cleaned_tweet']).with_format('tensorflow')
test_dataset = test_dataset.remove_columns(['tweet', 'cleaned_tweet']).with_format('tensorflow')

train_dataset

train_features = { x: train_dataset[x] for x in tokenizer.model_input_names }

train_features

import tensorflow as tf
train_set_for_final_model = tf.data.Dataset.from_tensor_slices((train_features, train_dataset['class']))

train_set_for_final_model = train_set_for_final_model.shuffle(buffer_size = len(train_set_for_final_model)).batch(4)

train_set_for_final_model

val_features = {x: valid_dataset[x] for x in tokenizer.model_input_names}
val_set_for_final_model = tf.data.Dataset.from_tensor_slices((val_features, valid_dataset['class']))
val_set_for_final_model = val_set_for_final_model.shuffle(buffer_size = len(val_set_for_final_model)).batch(4)


test_features = {x: test_dataset[x] for x in tokenizer.model_input_names}
test_set_for_final_model = tf.data.Dataset.from_tensor_slices((test_features, test_dataset['class']))
test_set_for_final_model = test_set_for_final_model.shuffle(buffer_size = len(test_set_for_final_model)).batch(4)

from transformers import TFAutoModelForSequenceClassification
model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-cased', num_labels = 3)

bert_model = model.bert

for layer in bert_model.encoder.layer[:-2]:
    layer.trainable = False

model.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = 5e-5),
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),
    metrics =[tf.keras.metrics.SparseCategoricalAccuracy()]
)

model.summary()

import tensorflow as tf

# Check GPU availability
physical_devices = tf.config.list_physical_devices('GPU')
print("Num GPUs Available:", len(physical_devices))

model.fit(train_set_for_final_model, validation_data = val_set_for_final_model, epochs = 3)

test_loss, test_acc = model.evaluate(test_set_for_final_model, verbose = 2)
print('Test Accuracy:', test_acc)

predict_score_and_class_dict = {
    0: 'Hate Speech',
    1: 'Offensive Language',
    2: 'Neither',
}

preds = model(tokenizer(['He is not a good guy, I dont why he is breathing, He sucks. Everthing about him sucks'], return_tensors = 'tf', padding = True, truncation = True))['logits']

print(model.predict)

predsp = model(tokenizer(['~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp; white. A Coll http://t.co/H0dYEBvnZB'], return_tensors = 'tf', padding = True, truncation = True))['logits']

predsp



