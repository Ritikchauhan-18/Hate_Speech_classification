# -*- coding: utf-8 -*-
"""Deep_learning_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FklsoD-2R_N2GTJMt-IetUz00x2nojcT
"""

import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('wordnet')
stopword = set(stopwords.words('english'))
import spacy
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Dropout
import tensorflow as tf
from tensorflow import keras

from keras.utils import to_categorical
from keras import backend as K

df = pd.read_excel("/content/hatespeechdata.xlsx")

df.head()

df.columns

df.drop(columns = ['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',],inplace=True)

df.head()

df.shape

df.dropna(axis = 0,inplace=True)

df.shape

def preprocess_data(text):
  text = str(text).lower()
  text = re.sub(r"@\w+:|@\w+",'',text)
  text = text.replace('rt','')
  text = re.sub('\[.*?\]','',text)
  text = re.sub('https?://\S+|www\.\S+','',text)
  text = re.sub('<.*?>+','',text)
  text = re.sub(r'[^\w\s]','',text)
  text = re.sub('\n','',text)
  text = re.sub('\w\d\w', '', text)
  text = [word for word in text.split(' ') if word not in stopword]
  text = " ".join(text)
  return text

df["Clean_tweet"] = df["tweet"].apply(preprocess_data)

df['Clean_tweet'][1000]

#NLP Spacy
nlp = spacy.load('en_core_web_sm')

def Lemma(text):
  lemma_text = nlp(text)
  lemma_list = [word.lemma_ for word in lemma_text]
  return ' '.join(lemma_list)

df['Lemma_tweet'] = df['Clean_tweet'].apply(Lemma)



vocab_size = 10000
one_hot_representation = [one_hot(words, vocab_size) for words in df['Lemma_tweet']]

one_hot_representation[0]

#padding
Sent_length = 20
Pad_sent = pad_sequences(one_hot_representation, padding='pre', maxlen=Sent_length)

X = np.array(Pad_sent)
Y = np.array(df['class'])

df['class'].value_counts()

#As the Target variable is Imbalanced
#So we use SMOTE to Balance
from imblearn.over_sampling import SMOTE

smote = SMOTE(sampling_strategy='minority')
X, Y = smote.fit_resample(X,Y)

#splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

y_train_one_hot = to_categorical(y_train, num_classes=3)
y_test_one_hot = to_categorical(y_test, num_classes=3)

print("X_train shape:", X_train.shape)  # Should be (num_samples, Sent_length)
print("y_train shape:", y_train.shape)    # Should be (num_samples,) if using sparse_categorical_crossentropy
print("X_test shape:", X_test.shape)      # Should match X_train
print("y_test shape:", y_test.shape)
y_train_one_hot.shape, y_test_one_hot.shape     # Should match y_train

deep_lr = Sequential()
deep_lr.add(Embedding(232337, 100, input_length=X_train.shape[1]))
deep_lr.add(SpatialDropout1D(0.2))
deep_lr.add(LSTM(20, dropout=0.2, recurrent_dropout=0.2))
deep_lr.add(Dense(3, activation='softmax'))
deep_lr.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

epochs = 25
batch_size = 64

history = deep_lr.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=epochs, batch_size=batch_size)

deep_lr = Sequential()
deep_lr.add(Embedding(10000, 100, input_length=X_train.shape[1]))
deep_lr.add(SpatialDropout1D(0.2))
deep_lr.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))
deep_lr.add(Dense(128, activation='relu'))
deep_lr.add(Dense(3, activation='softmax'))
deep_lr.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

epochs = 3
batch_size = 64

history = deep_lr.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=epochs, batch_size=batch_size)

!git clone https://github.com/Ritikchauhan-18/Hate_Speech_classification.git

# Commented out IPython magic to ensure Python compatibility.
# %cd Hate_Speech_classification

!git add deep_learning_model.py

!git commit -m "Add Deep_learning_model file from Colab"

!git config --global user.email "chauhansahab0852@gmail.com"
!git config --global user.name "Chauhan$18"

!git push origin main



